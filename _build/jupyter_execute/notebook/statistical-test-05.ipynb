{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfwbow7374Aj"
   },
   "source": [
    "# 様々な統計検定法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rpJbW90qhUJa"
   },
   "source": [
    "## パラメトリック"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dd2kkNbGUxSZ"
   },
   "source": [
    "パラメトリックとはデータが特定の確率分布に従い，その分布をパラメータ（確率分布の母数）で記述できることを意味します．つまり，データの背後にある確率分布の種類（正規分布やポアソン分布等）とそのパラメータを仮定して，それに基づいて分析を行う方法がパラメトリックな方法です．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5QwFPvyVOWH"
   },
   "source": [
    "```{note}\n",
    "母数とはパラメータの和訳です．母集団のサイズとか全数とか分母とかの意味はありませんのでご注意ください．\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P36tSaMrVpPe"
   },
   "source": [
    "これに対して，ノンパラメトリックとはデータの背後に確率分布を仮定しないという概念です．データの背後にある確率分布を仮定しない場合や異なる確率分布が混在している場合にパラメトリックな分析法が採用されます．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UvqcKzE1XakP"
   },
   "source": [
    "以下のコードではパラメトリック分析に適したデータとノンパラメトリック分析に適したデータを可視化します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "InsCNDjVWgoq"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "np.random.seed(0)\n",
    "\n",
    "def main():\n",
    "    # パラメトリック検定が適用できる正規分布\n",
    "    normal_data = np.random.normal(loc=50, scale=10, size=1000)\n",
    "\n",
    "    # ノンパラメトリック検定が適用されるデータ（分布の混合）\n",
    "    nonparametric_data = np.concatenate([\n",
    "        np.random.normal(loc=50, scale=10, size=500),  # 正規分布\n",
    "        np.random.exponential(scale=10, size=500)   # 指数分布（異なる分布を混合）\n",
    "    ])\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # パラメトリック分析に適したデータ\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(normal_data, bins=30, kde=True)\n",
    "    plt.title(\"Parametric\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "    # ノンパラメトリック分析に適したデータ\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.histplot(nonparametric_data, bins=30, kde=True, color=\"orange\")\n",
    "    plt.title(\"Nonparametric\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcNqhRBC8CIZ"
   },
   "source": [
    "## ノンパラメトリック検定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N0RC8xoD8Itm"
   },
   "source": [
    "## 統計検定の繰り返し"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BTP1AUXjdK8K"
   },
   "source": [
    "A，B，Cというの3群のサンプルデータがあるとき，これらの統計検定つまり，AB間，BC間，CA間の統計検定にt検定を繰り返し利用してはいけません．これらの3組の検定を2群間における3回のt検定で行う場合，少なくともひとつの組み合わせに差が出る確率 $p$ は以下の式で計算されます．\n",
    "\n",
    "$\n",
    "p= 1 - p_\\phi\n",
    "$\n",
    "\n",
    "ここで，$p_\\phi$ はすべての組み合わせで差が出ない確率です．今のようにA，B，Cという3群を考える場合，この $p_\\phi$ は以下のように計算されます．\n",
    "\n",
    "$\n",
    "p_\\phi=p_ap_bp_c\n",
    "$\n",
    "\n",
    "ここで $p_a$，$p_b$，$p_c$ はそれぞれ，AB間で差が出ない確率，BC間で差が出ない確率，CA間で差が出ない確率です．\n",
    "\n",
    "これに基づいて $p$ を計算すると，この値は各サンプルデータ間で差が出る確率より大きな数になります．例えば，各サンプルデータ間で差が出る確率を$0.01$とした場合，$p$ は以下のように計算されます．\n",
    "\n",
    "$\n",
    "1 - (1 - 0.01) * (1 - 0.01) * (1 - 0.01) = 0.029701\n",
    "$\n",
    "\n",
    "これは，各サンプルデータ間で差が出る確率として設定した0.01よりはるかに大きい値です．\n",
    "\n",
    "$\\alpha$ を群間で差が出る確率とおいたとき，少なくともひとつの組み合わせに差が出る確率は以下のようにあらわされます．\n",
    "\n",
    "$\n",
    "1 - (1 - \\alpha)^n\n",
    "$\n",
    "\n",
    "この値は $\\alpha$ を $0.05$ とし，$n$ を $10$ として計算すると $0.4013$ となります．これは，群間で差が出る確率がたとえ5%であったとしても検定を10回繰り返すと少なくともそれらの組み合わせて差が出る確率は約40%に達するということを意味します．統計検定を繰り返すと期待以上に有意な差が生じてしまうことになるのです．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n53qamiEhXPT"
   },
   "source": [
    "## 多重検定の補正"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uaYOUTyo3zFS"
   },
   "source": [
    "上記のように，複数回のt検定を繰り返すことで少なくとも1回は偶然に有意な差が出てしまう確率（多重比較による第一種の過誤）が増大してしまいます．これを防ぐために，多重比較の影響を考慮したボンフェローニ補正（Bonferroni correction）が用いられます．\n",
    "\n",
    "ボンフェローニ補正では，元の有意水準 $\\alpha$ を比較の回数 $n$ で割ることで各比較における有意水準を厳しく設定します．具体的には，新しい有意水準 $\\alpha'$ を次のように計算します．\n",
    "\n",
    "$\n",
    "\\alpha'=\\displaystyle\\frac{\\alpha}{n}\n",
    "$\n",
    "\n",
    "これによって，複数回の検定を行っても全体としての第一種の過誤（偽陽性）の確率を制御する子tができます．\n",
    "\n",
    "例えば、もともとの有意水準 $\\alpha=05$ で3回のt検定（AB間、BC間、CA間）を行う場合，補正後の有意水準は以下のようになります．\n",
    "\n",
    "$\n",
    "\\alpha'=\\displaystyle\\frac{0.05}{3}=0.0167\n",
    "$\n",
    "\n",
    "つまり，それぞれのt検定のp値が0.0167より小さくないと有意な差があるとは判断しません．ボンフェローニ補正は以下のように計算します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "uf6DteNa5Cef"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "np.random.seed(0)\n",
    "\n",
    "def main():\n",
    "    # ダミーデータの作成（3群: A, B, C）\n",
    "    A = np.random.normal(loc=50, scale=10, size=30)\n",
    "    B = np.random.normal(loc=55, scale=10, size=30)\n",
    "    C = np.random.normal(loc=60, scale=10, size=30)\n",
    "\n",
    "    # すべての組み合わせ（AB, BC, CA）でt検定\n",
    "    groups = {'A': A, 'B': B, 'C': C}\n",
    "    pairs = list(combinations(groups.keys(), 2))  # ('A', 'B'), ('A', 'C'), ('B', 'C')\n",
    "\n",
    "    # 有意水準\n",
    "    alpha = 0.05\n",
    "    n_tests = len(pairs)  # 検定回数\n",
    "    alpha_corrected = alpha / n_tests  # ボンフェローニ補正後の有意水準\n",
    "\n",
    "    # 検定の実施\n",
    "    results = []\n",
    "    for g1, g2 in pairs:\n",
    "        t_stat, p_value = stats.ttest_ind(groups[g1], groups[g2])\n",
    "        significant = p_value < alpha_corrected\n",
    "        results.append((g1, g2, p_value, significant))\n",
    "\n",
    "    df_results = pd.DataFrame(results, columns=[\"Group 1\", \"Group 2\", \"p-value\", \"Significant (Bonferroni)\"])\n",
    "    print(df_results.to_string(index=False))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrwsR78c58SH"
   },
   "source": [
    "## アドホックな多重検定法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFuIHm8f5_zx"
   },
   "source": [
    "ボンフェローニ補正は複数の検定を行う際に第一種過誤の確率を厳しく抑制するために用いられますが，その分非常に保守的で，有意差を見逃すリスクが高まります．この問題を緩和するために，より柔軟で検出力の高いアドホックな多重検定法がいくつか提案されています．ここでは，代表的な4つの方法を紹介します．\n",
    "\n",
    "| 方法名 | 適用場面 | 前提条件 |\n",
    "|---|---|---|\n",
    "| ダネット検定 | 対照群と複数の処置群の比較 | パラメトリック |\n",
    "| チューキー・クレーマー法 | すべての群間のペアワイズ比較 | パラメトリック |\n",
    "| スティール・ドゥワス法 | 対照群と複数の処置群の比較 | ノンパラメトリック |\n",
    "| ステールの方法 | すべての群間のペアワイズ比較 | ノンパラメトリック |\n",
    "\n",
    "ダネット検定は複数の処置群と対照群との比較に特化した方法です．対照群との比較のみを行うため，不必要なペアワイズ比較を省略でき，多重比較による誤検出のリスクを効果的に軽減できます．\n",
    "\n",
    "チューキー・クレーマー法はすべての群間でペアワイズ比較を行う場合に適用される手法です．各比較における統計量はt分布に基づいて計算され，ボンフェローニ補正よりも検出力に優れます．\n",
    "\n",
    "スティール・ドゥワス法はノンパラメトリックな多重比較法です．パラメトリックのダネット検定と同じく対照群と処置群の比較を行います．各群の順位情報を用いて統計量を算出します．\n",
    "\n",
    "ステールの方法はノンパラメトリックな枠組みで群間のペアワイズ比較をするための方法です．これも計算は順位情報に基づくため，正規性の仮定が満たされない場合に有用であり，外れ値の影響を受けにくい特徴を持ちます．\n",
    "\n",
    "これらの方法はどれもボンフェローニ補正と比べると保守性が低く，検出力を向上させる効果が期待できます．手法によって適用条件や前提が異なるため，解析の目的やデータの性質に応じて適切な方法を選択することが重要でしょう．"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}